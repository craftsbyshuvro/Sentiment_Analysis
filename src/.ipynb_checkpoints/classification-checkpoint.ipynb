{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Product Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:47.565559Z",
     "iopub.status.busy": "2021-08-07T08:45:47.564966Z",
     "iopub.status.idle": "2021-08-07T08:45:50.447122Z",
     "shell.execute_reply": "2021-08-07T08:45:50.446032Z",
     "shell.execute_reply.started": "2021-08-07T08:45:47.565441Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time, datetime\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.633756Z",
     "iopub.status.busy": "2021-08-07T08:45:50.633227Z",
     "iopub.status.idle": "2021-08-07T08:45:50.78613Z",
     "shell.execute_reply": "2021-08-07T08:45:50.785374Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.633726Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed-dataset.csv\")\n",
    "df = df.dropna(how='any',axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.787883Z",
     "iopub.status.busy": "2021-08-07T08:45:50.7874Z",
     "iopub.status.idle": "2021-08-07T08:45:53.108853Z",
     "shell.execute_reply": "2021-08-07T08:45:53.108016Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.787852Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=7000)\n",
    "features = vectorizer.fit_transform(df['text'])\n",
    "tf_idf = pd.DataFrame(features.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset into Train and Test Set\n",
    "We did 80:20 split for training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:53.110575Z",
     "iopub.status.busy": "2021-08-07T08:45:53.110087Z",
     "iopub.status.idle": "2021-08-07T08:45:54.219879Z",
     "shell.execute_reply": "2021-08-07T08:45:54.218686Z",
     "shell.execute_reply.started": "2021-08-07T08:45:53.110544Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tf_idf, df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:54.221536Z",
     "iopub.status.busy": "2021-08-07T08:45:54.221209Z",
     "iopub.status.idle": "2021-08-07T08:45:56.694186Z",
     "shell.execute_reply": "2021-08-07T08:45:56.693221Z",
     "shell.execute_reply.started": "2021-08-07T08:45:54.221508Z"
    }
   },
   "outputs": [],
   "source": [
    "yy=pd.DataFrame(y_train)\n",
    "train_data = pd.concat([X_train,yy],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling the Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:56.695594Z",
     "iopub.status.busy": "2021-08-07T08:45:56.695308Z",
     "iopub.status.idle": "2021-08-07T08:46:03.200407Z",
     "shell.execute_reply": "2021-08-07T08:46:03.199175Z",
     "shell.execute_reply.started": "2021-08-07T08:45:56.695566Z"
    }
   },
   "outputs": [],
   "source": [
    "target_count = train_data['sentiment'].value_counts()\n",
    "negative_class = train_data[train_data['sentiment'] == 0]\n",
    "positive_class = train_data[train_data['sentiment'] == 1]\n",
    "negative_over = negative_class.sample(target_count[1], replace=True)\n",
    "df_train_over = pd.concat([positive_class, negative_over], axis=0)\n",
    "df_train_over = shuffle(df_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:46:03.202073Z",
     "iopub.status.busy": "2021-08-07T08:46:03.201759Z",
     "iopub.status.idle": "2021-08-07T08:46:03.373758Z",
     "shell.execute_reply": "2021-08-07T08:46:03.372729Z",
     "shell.execute_reply.started": "2021-08-07T08:46:03.202044Z"
    }
   },
   "outputs": [],
   "source": [
    "counts=df_train_over['sentiment'].value_counts()\n",
    "plt.title(\"Train Classes count after Oversampling\")\n",
    "plt.bar(counts.index, counts.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Data for Train-Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:46:03.375516Z",
     "iopub.status.busy": "2021-08-07T08:46:03.375107Z",
     "iopub.status.idle": "2021-08-07T08:46:03.385446Z",
     "shell.execute_reply": "2021-08-07T08:46:03.38419Z",
     "shell.execute_reply.started": "2021-08-07T08:46:03.375482Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train=df_train_over.iloc[:,:-1]\n",
    "y_train=df_train_over['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:46:03.387669Z",
     "iopub.status.busy": "2021-08-07T08:46:03.387231Z",
     "iopub.status.idle": "2021-08-07T08:46:03.395787Z",
     "shell.execute_reply": "2021-08-07T08:46:03.394751Z",
     "shell.execute_reply.started": "2021-08-07T08:46:03.387627Z"
    }
   },
   "outputs": [],
   "source": [
    "Here we are defining our models with list of values for parameters to find the best value using GridSearchCV\n",
    "models_with_default_params=[{'mod' : MultinomialNB(), 'param': {'alpha': [10**-5,10**-4,10**-3,10**-2,10**-1,1,1.5,2]}},\n",
    "                            {'mod': LinearSVC(), 'param': {'C': [0.1, 1, 10]}},\n",
    "                            {'mod': KNeighborsClassifier(), 'param': {'n_neighbors': [1,2,3]}},\n",
    "                            {'mod': XGBClassifier(), 'param': {'n_estimators': [100]}}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:46:03.39733Z",
     "iopub.status.busy": "2021-08-07T08:46:03.397027Z",
     "iopub.status.idle": "2021-08-07T08:46:05.345421Z",
     "shell.execute_reply": "2021-08-07T08:46:05.344617Z",
     "shell.execute_reply.started": "2021-08-07T08:46:03.397301Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.replace(np.NaN, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Chi-Square Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:46:05.346919Z",
     "iopub.status.busy": "2021-08-07T08:46:05.346654Z",
     "iopub.status.idle": "2021-08-07T08:46:05.351005Z",
     "shell.execute_reply": "2021-08-07T08:46:05.350066Z",
     "shell.execute_reply.started": "2021-08-07T08:46:05.346894Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_vect = X_train\n",
    "X_test_vect = X_test\n",
    "\n",
    "for mwdp in models_with_default_params:\n",
    "    SVM_grid_search = GridSearchCV(mwdp['mod'], mwdp['param'], refit=True, verbose=3)\n",
    "    SVM_grid_search.fit(X_train_vect, y_train)\n",
    "\n",
    "    #considering the best model using GridSearchCV\n",
    "    model = SVM_grid_search.best_estimator_\n",
    "\n",
    "    print('---------'+'Model: '+model.__class__.__name__+'---------')\n",
    "    print('Feature Vector Size:',X_train_vect.shape)\n",
    "    print('Best Model: ',model)\n",
    "\n",
    "    train_start_time = datetime.datetime.now()\n",
    "    model.fit(X_train_vect, y_train)\n",
    "    print('TRAIN TIME: ', datetime.datetime.now() - train_start_time)\n",
    "\n",
    "    y_pred = model.predict(X_test_vect)\n",
    "\n",
    "\n",
    "    print('Accuracy: ',accuracy_score(y_test, y_pred))\n",
    "    print('Precision: ',precision_score(y_test, y_pred, average=\"macro\"))\n",
    "    print('Recall: ',recall_score(y_test, y_pred, average=\"macro\"))\n",
    "    print('F1 Score: ',f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Chi-Square Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:46:05.352594Z",
     "iopub.status.busy": "2021-08-07T08:46:05.352299Z",
     "iopub.status.idle": "2021-08-07T08:46:46.411661Z",
     "shell.execute_reply": "2021-08-07T08:46:46.409823Z",
     "shell.execute_reply.started": "2021-08-07T08:46:05.352567Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_vect = X_train\n",
    "X_test_vect = X_test\n",
    "\n",
    "chi_selector = SelectKBest(score_func=chi2, k=500)\n",
    "X_train_vect_chi=chi_selector.fit_transform(X_train_vect, y_train)\n",
    "X_test_vect_chi=chi_selector.transform(X_test_vect)\n",
    "\n",
    "\n",
    "for mwdp in models_with_default_params:\n",
    "    SVM_grid_search = GridSearchCV(mwdp['mod'], mwdp['param'], refit=True, verbose=3)\n",
    "    SVM_grid_search.fit(X_train_vect_chi, y_train)\n",
    "\n",
    "    #considering the best model using GridSearchCV\n",
    "    model = SVM_grid_search.best_estimator_\n",
    "\n",
    "    print('---------'+'Model: '+model.__class__.__name__+'---------')\n",
    "    print('Feature Vector Size:',X_train_vect_chi.shape)\n",
    "    print('Best Model: ',model)\n",
    "\n",
    "    train_start_time = datetime.datetime.now()\n",
    "    model.fit(X_train_vect_chi, y_train)\n",
    "    print('TRAIN TIME: ', datetime.datetime.now() - train_start_time)\n",
    "\n",
    "    y_pred = model.predict(X_test_vect_chi)  \n",
    "\n",
    "\n",
    "    print('Accuracy: ',accuracy_score(y_test, y_pred))\n",
    "    print('Precision: ',precision_score(y_test, y_pred, average=\"macro\"))\n",
    "    print('Recall: ',recall_score(y_test, y_pred, average=\"macro\"))\n",
    "    print('F1 Score: ',f1_score(y_test, y_pred, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
