{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:47.565559Z",
     "iopub.status.busy": "2021-08-07T08:45:47.564966Z",
     "iopub.status.idle": "2021-08-07T08:45:50.447122Z",
     "shell.execute_reply": "2021-08-07T08:45:50.446032Z",
     "shell.execute_reply.started": "2021-08-07T08:45:47.565441Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time, datetime\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.449117Z",
     "iopub.status.busy": "2021-08-07T08:45:50.448748Z",
     "iopub.status.idle": "2021-08-07T08:45:50.453148Z",
     "shell.execute_reply": "2021-08-07T08:45:50.452136Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.449057Z"
    }
   },
   "outputs": [],
   "source": [
    "data1_path = '/kaggle/input/consumer-reviews-of-amazon-products/1429_1.csv'\n",
    "data2_path = \"/kaggle/input/consumer-reviews-of-amazon-products/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\"\n",
    "data3_path = \"/kaggle/input/consumer-reviews-of-amazon-products/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(data1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.455386Z",
     "iopub.status.busy": "2021-08-07T08:45:50.454857Z",
     "iopub.status.idle": "2021-08-07T08:45:50.464688Z",
     "shell.execute_reply": "2021-08-07T08:45:50.463857Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.455344Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "data1['reviews.rating'].value_counts().sort_values().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is a huge imbalnce in the dataset\n",
    "Need to add more data with low rate classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.466876Z",
     "iopub.status.busy": "2021-08-07T08:45:50.466328Z",
     "iopub.status.idle": "2021-08-07T08:45:50.475415Z",
     "shell.execute_reply": "2021-08-07T08:45:50.474553Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.466823Z"
    }
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(data2_path)\n",
    "data2 = data2[['reviews.rating' , 'reviews.text']]\n",
    "data2 = data2[data2[\"reviews.rating\"]<=3]\n",
    "\n",
    "data3 = pd.read_csv(data3_path)\n",
    "data3 = data3[['reviews.rating' , 'reviews.text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.479801Z",
     "iopub.status.busy": "2021-08-07T08:45:50.479498Z",
     "iopub.status.idle": "2021-08-07T08:45:50.485538Z",
     "shell.execute_reply": "2021-08-07T08:45:50.48481Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.479771Z"
    }
   },
   "outputs": [],
   "source": [
    "#Only considering those where rating is equal or less than 3\n",
    "data2 = data2[data2[\"reviews.rating\"]<=3]\n",
    "data3 = data3[data3[\"reviews.rating\"]<=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the datasets\n",
    "data=pd.concat([data1, data2, data3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.503895Z",
     "iopub.status.busy": "2021-08-07T08:45:50.503408Z",
     "iopub.status.idle": "2021-08-07T08:45:50.51178Z",
     "shell.execute_reply": "2021-08-07T08:45:50.510956Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.503853Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.concat([data['reviews.text'],data['reviews.rating']], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.513913Z",
     "iopub.status.busy": "2021-08-07T08:45:50.513336Z",
     "iopub.status.idle": "2021-08-07T08:45:50.521422Z",
     "shell.execute_reply": "2021-08-07T08:45:50.520718Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.513871Z"
    }
   },
   "outputs": [],
   "source": [
    "df['reviews.rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.522496Z",
     "iopub.status.busy": "2021-08-07T08:45:50.522187Z",
     "iopub.status.idle": "2021-08-07T08:45:50.531659Z",
     "shell.execute_reply": "2021-08-07T08:45:50.5308Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.522469Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df=df.reset_index()\n",
    "df.drop(columns=['index'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.53321Z",
     "iopub.status.busy": "2021-08-07T08:45:50.532871Z",
     "iopub.status.idle": "2021-08-07T08:45:50.541853Z",
     "shell.execute_reply": "2021-08-07T08:45:50.541112Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.533183Z"
    }
   },
   "outputs": [],
   "source": [
    "df['reviews.rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.543364Z",
     "iopub.status.busy": "2021-08-07T08:45:50.543034Z",
     "iopub.status.idle": "2021-08-07T08:45:50.552089Z",
     "shell.execute_reply": "2021-08-07T08:45:50.551156Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.543335Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment = {1: 0,\n",
    "            2: 0,\n",
    "            3: 0,\n",
    "            4: 1,\n",
    "            5: 1}\n",
    "df['sentiment']=df['reviews.rating'].map(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.553597Z",
     "iopub.status.busy": "2021-08-07T08:45:50.553299Z",
     "iopub.status.idle": "2021-08-07T08:45:50.563601Z",
     "shell.execute_reply": "2021-08-07T08:45:50.562574Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.55357Z"
    }
   },
   "outputs": [],
   "source": [
    "df['sentiment'].value_counts().sort_values().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.56525Z",
     "iopub.status.busy": "2021-08-07T08:45:50.564918Z",
     "iopub.status.idle": "2021-08-07T08:45:50.575432Z",
     "shell.execute_reply": "2021-08-07T08:45:50.574436Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.565222Z"
    }
   },
   "outputs": [],
   "source": [
    "positiveWords = pd.Series(' '.join(df[df['sentiment']==1]['reviews.text']).split())\n",
    "wordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(positiveWords))\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.title(\"Most Positive Words Used \")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.577151Z",
     "iopub.status.busy": "2021-08-07T08:45:50.576789Z",
     "iopub.status.idle": "2021-08-07T08:45:50.587979Z",
     "shell.execute_reply": "2021-08-07T08:45:50.586736Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.577121Z"
    }
   },
   "outputs": [],
   "source": [
    "negativeWords=words = pd.Series(' '.join(df[df['sentiment']==0]['reviews.text']).split())\n",
    "wordcloud = WordCloud(width = 1000, height = 500).generate(' '.join(negativeWords))\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.title(\"Most Negative Words Used \")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions for Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.589783Z",
     "iopub.status.busy": "2021-08-07T08:45:50.589456Z",
     "iopub.status.idle": "2021-08-07T08:45:50.599217Z",
     "shell.execute_reply": "2021-08-07T08:45:50.598378Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.589754Z"
    }
   },
   "outputs": [],
   "source": [
    "all_text_data = np.array(df['reviews.text'])\n",
    "\n",
    "all_urls = []\n",
    "for i in tqdm(range(0,df.shape[0])):\n",
    "    r = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    urls = r.findall(all_text_data[i])\n",
    "    all_urls = all_urls + urls\n",
    "\n",
    "print('Total URLS: ', len(all_urls),'\\n\\n')\n",
    "    \n",
    "\n",
    "all_tags = []\n",
    "for i in tqdm(range(0,df.shape[0])):\n",
    "    r = re.compile('<.*?>')\n",
    "    tags = r.findall(all_text_data[i])\n",
    "    all_tags = all_tags + tags\n",
    "    \n",
    "print('Total Tags: ', len(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.600729Z",
     "iopub.status.busy": "2021-08-07T08:45:50.600413Z",
     "iopub.status.idle": "2021-08-07T08:45:50.609029Z",
     "shell.execute_reply": "2021-08-07T08:45:50.608182Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.600704Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "# \n",
    "def remove_tags(html):\n",
    "    # parse html content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "  \n",
    "    for data in soup(['style', 'script']):\n",
    "        # Remove tags\n",
    "        data.decompose()\n",
    "    # return data by retrieving the tag content\n",
    "    return ' '.join(soup.stripped_strings)\n",
    "\n",
    "def remove_link_from(text):\n",
    "    URLless_string = re.sub(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}     /)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', text)\n",
    "    return URLless_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-07T08:45:50.610795Z",
     "iopub.status.busy": "2021-08-07T08:45:50.610499Z",
     "iopub.status.idle": "2021-08-07T08:45:50.622245Z",
     "shell.execute_reply": "2021-08-07T08:45:50.621482Z",
     "shell.execute_reply.started": "2021-08-07T08:45:50.61077Z"
    }
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "corpus=[]\n",
    "\n",
    "for i in tqdm(range(0,len(df['reviews.text']))):\n",
    "    #Data Cleaning only considerin the alphabets\n",
    "    review = re.sub(\"[^a-zA-Z]\",\" \",df['reviews.text'][i])\n",
    "    \n",
    "    #Lowering the cases\n",
    "    review = review.lower()\n",
    "    \n",
    "    #Removing Links from texts\n",
    "    review = remove_link_from(review)\n",
    "    \n",
    "    #Removing tags from texts\n",
    "    review = remove_tags(review)\n",
    "    \n",
    "    #Splitting sentence into words\n",
    "    review = review.split()\n",
    "    \n",
    "    #Stemming\n",
    "    #Stropwords removing\n",
    "    review = [ps.stem(word) for word in review if word not in stopwords.words(\"english\")]\n",
    "    \n",
    "    #Joining the words again\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    df['reviews.text'][i] = review\n",
    "    \n",
    "df['text']=df['reviews.text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = {\"text\": df['text'], \"sentiment\": df['sentiment']}\n",
    "processed_df = pd.DataFrame(processed_data)\n",
    "processed_df.to_csv('preprocessed-dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
